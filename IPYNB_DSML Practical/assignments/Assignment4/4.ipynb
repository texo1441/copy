{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d90c6985",
   "metadata": {},
   "source": [
    "Write a program to do: A dataset collected in a cosmetics shop showing\n",
    "details of customers and whether or not they responded to a special offer\n",
    "to buy a new lip-stick is shown in table below. (Implement step by step\n",
    "using commands - Dont use library) Use this dataset to build a decision\n",
    "tree, with Buys as the target variable, to help in buying lipsticks in the\n",
    "future. Find the root node of the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df4df7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "      Age  Income  Gender       Ms Buys\n",
      "0     <21    High    Male   Single   No\n",
      "1     <21    High    Male  Married   No\n",
      "2   21-35    High    Male   Single  Yes\n",
      "3     >35  Medium    Male   Single  Yes\n",
      "4     >35     Low  Female   Single  Yes\n",
      "5     >35     Low  Female  Married   No\n",
      "6   21-35     Low  Female  Married  Yes\n",
      "7     <21  Medium    Male   Single   No\n",
      "8     <21     Low  Female  Married  Yes\n",
      "9     >35  Medium  Female   Single  Yes\n",
      "10    <21  Medium  Female  Married  Yes\n",
      "11  21-35  Medium    Male  Married  Yes\n",
      "12  21-35    High  Female   Single  Yes\n",
      "13    >35  Medium    Male  Married   No\n",
      "\n",
      "Columns: ['Age', 'Income', 'Gender', 'Ms', 'Buys']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Lipstick.csv')\n",
    "\n",
    "# Drop 'Id' column as it is not a feature\n",
    "df = df.drop('Id', axis=1)\n",
    "\n",
    "print(\"Dataset:\")\n",
    "print(df)\n",
    "print(\"\\nColumns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "842cc566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data, target_col):\n",
    "    \"\"\"\n",
    "    Calculates the Shannon Entropy of a dataset for a given target column.\n",
    "    Formula: H(S) = -sum(p_i * log2(p_i))\n",
    "    \"\"\"\n",
    "    # Get all unique values in the target column (e.g., 'Yes', 'No')\n",
    "    values = data[target_col].unique()\n",
    "    entropy = 0\n",
    "    total_count = len(data)\n",
    "    \n",
    "    for value in values:\n",
    "        # Count how many times this value appears\n",
    "        count = len(data[data[target_col] == value])\n",
    "        # Calculate probability p_i\n",
    "        probability = count / total_count\n",
    "        # Add to entropy formula\n",
    "        entropy += -probability * math.log2(probability)\n",
    "        \n",
    "    return entropy\n",
    "\n",
    "def calculate_information_gain(data, attribute, target_col):\n",
    "    \"\"\"\n",
    "    Calculates the Information Gain of a specific attribute.\n",
    "    Formula: Gain(S, A) = Entropy(S) - Sum((|Sv|/|S|) * Entropy(Sv))\n",
    "    \"\"\"\n",
    "    # 1. Calculate Total Entropy of the entire set\n",
    "    total_entropy = calculate_entropy(data, target_col)\n",
    "    \n",
    "    # 2. Calculate Weighted Entropy of the attribute\n",
    "    values = data[attribute].unique()\n",
    "    weighted_entropy = 0\n",
    "    total_count = len(data)\n",
    "    \n",
    "    # Loop through each unique value of the attribute (e.g., 'High', 'Medium', 'Low')\n",
    "    for value in values:\n",
    "        # Create a subset of data where the attribute equals this value\n",
    "        subset = data[data[attribute] == value]\n",
    "        \n",
    "        # Calculate the weight (|Sv|/|S|)\n",
    "        weight = len(subset) / total_count\n",
    "        \n",
    "        # Calculate entropy of this subset\n",
    "        subset_entropy = calculate_entropy(subset, target_col)\n",
    "        \n",
    "        # Add to the weighted entropy sum\n",
    "        weighted_entropy += weight * subset_entropy\n",
    "        \n",
    "    # 3. Calculate Information Gain\n",
    "    information_gain = total_entropy - weighted_entropy\n",
    "    return information_gain, total_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0169c712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Calculating Information Gain for Target: 'Buys' ---\n",
      "\n",
      "Feature: Age\n",
      "  Total Entropy:    0.9403\n",
      "  Information Gain: 0.2467\n",
      "------------------------------\n",
      "Feature: Income\n",
      "  Total Entropy:    0.9403\n",
      "  Information Gain: 0.0292\n",
      "------------------------------\n",
      "Feature: Gender\n",
      "  Total Entropy:    0.9403\n",
      "  Information Gain: 0.1518\n",
      "------------------------------\n",
      "Feature: Ms\n",
      "  Total Entropy:    0.9403\n",
      "  Information Gain: 0.0161\n",
      "------------------------------\n",
      "\n",
      "RESULT: The Root Node is 'Age' with the highest Information Gain of 0.2467\n"
     ]
    }
   ],
   "source": [
    "# Define the target variable and features\n",
    "target_col = 'Buys'\n",
    "features = [col for col in df.columns if col != target_col]\n",
    "\n",
    "best_gain = -1\n",
    "root_node = None\n",
    "\n",
    "print(f\"--- Calculating Information Gain for Target: '{target_col}' ---\\n\")\n",
    "\n",
    "# Loop through each feature to calculate its Information Gain\n",
    "for feature in features:\n",
    "    gain, total_entropy = calculate_information_gain(df, feature, target_col)\n",
    "    \n",
    "    print(f\"Feature: {feature}\")\n",
    "    print(f\"  Total Entropy:    {total_entropy:.4f}\")\n",
    "    print(f\"  Information Gain: {gain:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Check if this is the best gain so far\n",
    "    if gain > best_gain:\n",
    "        best_gain = gain\n",
    "        root_node = feature\n",
    "\n",
    "print(f\"\\nRESULT: The Root Node is '{root_node}' with the highest Information Gain of {best_gain:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b570be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Full Decision Tree Structure ---\n",
      "Node: Age (Gain: 0.2467)\n",
      "-> Branch: <21\n",
      "  Node: Gender (Gain: 0.9710)\n",
      "  -> Branch: Male\n",
      "    Leaf: No\n",
      "  -> Branch: Female\n",
      "    Leaf: Yes\n",
      "-> Branch: 21-35\n",
      "  Leaf: Yes\n",
      "-> Branch: >35\n",
      "  Node: Ms (Gain: 0.9710)\n",
      "  -> Branch: Single\n",
      "    Leaf: Yes\n",
      "  -> Branch: Married\n",
      "    Leaf: No\n"
     ]
    }
   ],
   "source": [
    "def build_tree(data, features, target_col, level=0):\n",
    "    \"\"\"\n",
    "    Recursive function to build the full decision tree structure.\n",
    "    \"\"\"\n",
    "    indent = \"  \" * level\n",
    "    \n",
    "    # Base Case 1: If all target values are the same, return that value (Leaf Node)\n",
    "    unique_targets = data[target_col].unique()\n",
    "    if len(unique_targets) == 1:\n",
    "        print(f\"{indent}Leaf: {unique_targets[0]}\")\n",
    "        return\n",
    "    \n",
    "    # Base Case 2: If no features left, return the most common target value\n",
    "    if len(features) == 0:\n",
    "        most_common = data[target_col].mode()[0]\n",
    "        print(f\"{indent}Leaf: {most_common}\")\n",
    "        return\n",
    "\n",
    "    # Find the best feature to split on\n",
    "    best_gain = -1\n",
    "    best_feature = None\n",
    "    \n",
    "    for feature in features:\n",
    "        gain, _ = calculate_information_gain(data, feature, target_col)\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_feature = feature\n",
    "            \n",
    "    print(f\"{indent}Node: {best_feature} (Gain: {best_gain:.4f})\")\n",
    "    \n",
    "    # Recursively build tree for each value of the best feature\n",
    "    remaining_features = [f for f in features if f != best_feature]\n",
    "    \n",
    "    for value in data[best_feature].unique():\n",
    "        print(f\"{indent}-> Branch: {value}\")\n",
    "        subset = data[data[best_feature] == value]\n",
    "        build_tree(subset, remaining_features, target_col, level + 1)\n",
    "\n",
    "print(\"--- Full Decision Tree Structure ---\")\n",
    "build_tree(df, features, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cf0e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad1b157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
